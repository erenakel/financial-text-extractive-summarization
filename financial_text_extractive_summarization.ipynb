{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "h71fhP9uZpfS",
        "Y8cpXFa9e1fS",
        "SNnfi8R-ncHl",
        "HCtTPZJS0VY5"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extractive Summarization for Financial Texts"
      ],
      "metadata": {
        "id": "-EMib9NiZK0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Imports & Preprocessing"
      ],
      "metadata": {
        "id": "h71fhP9uZpfS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F3C51d1Yz4-",
        "outputId": "cddc82e1-6274-4336-80de-04be15ac0908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk # NLP\n",
        "import re # for text cleaning\n",
        "import numpy as np\n",
        "\n",
        "# Necessary NLP resources (stopwords & tokenizer)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords') # unimportant words\n",
        "nltk.download('punkt_tab') # tokenizer data required to split sentences\n",
        "\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a function for preprocessing\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "  # clear spaces\n",
        "  text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "  # Remove reference numbers like [1], [2]\n",
        "  text = text = re.sub(r'\\[[0-9]*\\]', ' ', text)\n",
        "\n",
        "  # Separation into sentences (Tokenization)\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "  return sentences"
      ],
      "metadata": {
        "id": "D4cgSWVxao5u"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test for preprocess_text func\n",
        "\n",
        "text = \"\"\"Apple Inc. (AAPL) reported its quarterly earnings today, exceeding analyst expectations.\n",
        "Revenue increased by 12% year-over-year, driven by strong iPhone sales and growing services revenue.\n",
        "The company also announced a $90 billion share buyback program. Investors reacted positively, pushing the stock price up by 4% in after-hours trading.\n",
        "However, concerns remain about potential supply chain disruptions due to global chip shortages.\"\"\"\n",
        "\n",
        "sentences = preprocess_text(text)\n",
        "print(\"Cleaned Sentences:\\n\", sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3x-DE9mbroB",
        "outputId": "7ef4c828-5afe-4923-f8b5-b6258fe5cd82"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Sentences:\n",
            " ['Apple Inc. (AAPL) reported its quarterly earnings today, exceeding analyst expectations.', 'Revenue increased by 12% year-over-year, driven by strong iPhone sales and growing services revenue.', 'The company also announced a $90 billion share buyback program.', 'Investors reacted positively, pushing the stock price up by 4% in after-hours trading.', 'However, concerns remain about potential supply chain disruptions due to global chip shortages.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of this section:\n",
        "\n",
        "- We cleaned the text and divided it into sentences.\n",
        "\n",
        "- We created a correct structure without damaging the numbers and punctuation marks.\n",
        "\n",
        "Next Up: Analyzing sentences with TF-IDF and determining their importance levels"
      ],
      "metadata": {
        "id": "SsCmbyPieiFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Analyzing Sentences with TF-IDF"
      ],
      "metadata": {
        "id": "Y8cpXFa9e1fS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF - IDF meaning:\n",
        "\n",
        "- TF (Term Frequency): Measures how many times a word occurs in a given sentence.\n",
        "\n",
        "- IDF (Inverse Document Frequency): Calculates how rare or common the word is.\n",
        "\n",
        "Result: If a word is both frequent (TF high) and rare (IDF high), that word is considered important."
      ],
      "metadata": {
        "id": "XUfx0w2tfT3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute score function\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def compute_sentence_scores(sentences, ngram=(1,2)):\n",
        "\n",
        "  # Remove English stopwords\n",
        "  vectorizer = TfidfVectorizer(stop_words='english', ngram_range= ngram)\n",
        "\n",
        "  # Convert sentences to TF-IDF matrix\n",
        "  sentence_vectors = vectorizer.fit_transform(sentences).toarray()\n",
        "\n",
        "  # Calculate the average TF-IDF score for each sentence\n",
        "  sentence_scores = np.mean(sentence_vectors, axis=1)\n",
        "\n",
        "  return sentence_scores"
      ],
      "metadata": {
        "id": "EUfOE4oWfhcg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is N-gram and How to Choose It?\n",
        "\n",
        "In TF-IDF, the ngram_range=(a, b) setting determines:\n",
        "\n",
        "- (1,1): Unigram (Single Words): “Apple”, “reported”, “earnings”\n",
        "\n",
        "- (1,2): Unigram + Bigram (Single and Binary Words): “Apple”, “reported”, “Apple reported”, “reported earnings”\n",
        "- (2,2): Only Bigram (Binary Word Groups): “Apple reported”, “reported earnings”, “earnings today”\n",
        "- (2,3): Bigram + Trigram (Binary and Triple Word Groups): “Apple reported”, “reported earnings”, “Apple reported earnings”, “reported earnings today”\n",
        "- (3,3): Only Trigram (Triple Word Groups): “Apple reported earnings”, “reported earnings today”"
      ],
      "metadata": {
        "id": "obziJwOLlHko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tests for ngram results\n",
        "\n",
        "# Unigram\n",
        "scores_unigram = compute_sentence_scores(sentences, ngram=(1,1))\n",
        "\n",
        "# Unigram + Bigram\n",
        "scores_bigram = compute_sentence_scores(sentences, ngram=(1,2))\n",
        "\n",
        "# Bigram + Trigram\n",
        "scores_trigram = compute_sentence_scores(sentences, ngram=(2,3))\n",
        "\n",
        "print(\"Unigram:\", scores_unigram)\n",
        "print(\"Bigram:\", scores_bigram)\n",
        "print(\"Trigram:\", scores_trigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sswlXFavmKu3",
        "outputId": "038c0e81-cb91-4dd3-90a9-fb7fb23bbe20"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram: [0.04342    0.04347826 0.03834422 0.04093061 0.04342    0.04577435\n",
            " 0.03827988 0.05015279]\n",
            "Bigram: [0.03051895 0.03278779 0.02670779 0.02866488 0.03051895 0.03226669\n",
            " 0.02668233 0.03550505]\n",
            "Trigram: [0.03123374 0.03695626 0.02674697 0.02907703 0.03123374 0.03325085\n",
            " 0.02674697 0.03695626]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose (1,2) because it provides a good balance for understanding the\n",
        "context.\n",
        "\n",
        "- It has the ability to understand the context of the word (thanks to bigrams)\n",
        "- It does not require much calculation (not like trigrams)\n",
        "- It can also work well in shorter sentences"
      ],
      "metadata": {
        "id": "9ResWzF8loNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "sentence_vectors = vectorizer.fit_transform(sentences).toarray()\n",
        "```\n",
        "\n",
        "It converts each sentence into a numeric vector with TF-IDF values and allows us to represent sentences mathematically.\n",
        "\n",
        "```\n",
        "\"Apple earnings increased by 12%\" → [0.1, 0.2, 0.5, 0.3, 0.0, ...]\n",
        "\"Investors reacted positively\" → [0.0, 0.1, 0.4, 0.7, 0.0, ...]\n",
        "```"
      ],
      "metadata": {
        "id": "MLj2US_iga73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test for compute_sentence_scores func\n",
        "\n",
        "text = \"\"\"\n",
        "Apple Inc. (AAPL) reported its quarterly earnings today, exceeding analyst expectations.\n",
        "Revenue increased by 12% year-over-year, driven by strong iPhone sales and growing services revenue.\n",
        "The company also announced a $90 billion share buyback program.\n",
        "Investors reacted positively, pushing the stock price up by 4% in after-hours trading.\n",
        "However, concerns remain about potential supply chain disruptions due to global chip shortages.\n",
        "Meanwhile, the technology sector showed mixed results as Microsoft and Google reported varying performance.\n",
        "Some analysts remain cautious about inflation and its impact on consumer spending.\n",
        "The Federal Reserve's recent interest rate decision is expected to influence stock market trends in the coming weeks.\n",
        "\"\"\"\n",
        "\n",
        "sentences = preprocess_text(text)\n",
        "\n",
        "sentence_scores = compute_sentence_scores(sentences)\n",
        "\n",
        "for i, score in enumerate(sentence_scores):\n",
        "\n",
        "    print(f\"Sentence {i+1}: {sentences[i]}\")\n",
        "\n",
        "    print(f\"Score: {score}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi_mAfephDzJ",
        "outputId": "5b7f91d2-9c04-463b-9e14-8f8392bc0250"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1:  Apple Inc. (AAPL) reported its quarterly earnings today, exceeding analyst expectations.\n",
            "Score: 0.030518953467132133\n",
            "\n",
            "Sentence 2: Revenue increased by 12% year-over-year, driven by strong iPhone sales and growing services revenue.\n",
            "Score: 0.03278779306508986\n",
            "\n",
            "Sentence 3: The company also announced a $90 billion share buyback program.\n",
            "Score: 0.026707787225659183\n",
            "\n",
            "Sentence 4: Investors reacted positively, pushing the stock price up by 4% in after-hours trading.\n",
            "Score: 0.028664880625958518\n",
            "\n",
            "Sentence 5: However, concerns remain about potential supply chain disruptions due to global chip shortages.\n",
            "Score: 0.030518953467132133\n",
            "\n",
            "Sentence 6: Meanwhile, the technology sector showed mixed results as Microsoft and Google reported varying performance.\n",
            "Score: 0.03226669211849623\n",
            "\n",
            "Sentence 7: Some analysts remain cautious about inflation and its impact on consumer spending.\n",
            "Score: 0.026682331857952716\n",
            "\n",
            "Sentence 8: The Federal Reserve's recent interest rate decision is expected to influence stock market trends in the coming weeks.\n",
            "Score: 0.0355050508938018\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of this section:\n",
        "\n",
        "- We converted the sentences in the text to numerical vectors with TF-IDF.\n",
        "\n",
        "- We calculated scores using unigram, bigram and trigram to determine the importance of the sentences.\n",
        "\n",
        "- We chose the “Unigram + Bigram (1,2)” model that gave the best results and will use it for summarization.\n",
        "\n",
        "Next Up: Choosing the Most Important Sentences"
      ],
      "metadata": {
        "id": "CRe8zYlHnIaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Choosing the Most Important Sentences"
      ],
      "metadata": {
        "id": "SNnfi8R-ncHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq # To select the highest scoring sentences\n",
        "\n",
        "def select_top_sentences(sentences, sentence_scores, num_sentences = 3):\n",
        "\n",
        "  # Get indexes of sentences with highest scores\n",
        "  top_sentence_indices = heapq.nlargest(num_sentences, range(len(sentence_scores)), key=sentence_scores.__getitem__)\n",
        "\n",
        "  # Return sentences sorted in original order\n",
        "  summary_sentences = [sentences[i] for i in sorted(top_sentence_indices)]\n",
        "\n",
        "  return ' '.join(summary_sentences) # merge"
      ],
      "metadata": {
        "id": "rOWvPXDvneJE"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "\n",
        "text = \"\"\"Apple Inc. (AAPL) reported its quarterly earnings today, exceeding analyst expectations.\n",
        "Revenue increased by 12% year-over-year, driven by strong iPhone sales and growing services revenue.\n",
        "The company also announced a $90 billion share buyback program. Investors reacted positively, pushing the stock price up by 4% in after-hours trading.\n",
        "However, concerns remain about potential supply chain disruptions due to global chip shortages.\n",
        "Meanwhile, the technology sector showed mixed results as Microsoft and Google reported varying performance.\n",
        "Some analysts remain cautious about inflation and its impact on consumer spending.\n",
        "The Federal Reserve's recent interest rate decision is expected to influence stock market trends in the coming weeks.\n",
        "\"\"\"\n",
        "\n",
        "sentences = preprocess_text(text)\n",
        "\n",
        "sentence_scores = compute_sentence_scores(sentences, ngram=(1,2))\n",
        "\n",
        "summary = select_top_sentences(sentences, sentence_scores, num_sentences=3)\n",
        "\n",
        "print(\"Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwnZkzTYnhcG",
        "outputId": "111737a0-b9e4-4c2c-f054-07f0e07a7016"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " Revenue increased by 12% year-over-year, driven by strong iPhone sales and growing services revenue. Meanwhile, the technology sector showed mixed results as Microsoft and Google reported varying performance. The Federal Reserve's recent interest rate decision is expected to influence stock market trends in the coming weeks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CZ9DDNxtzfJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of this section:\n",
        "\n",
        "- We identified the most important sentences using TF-IDF scores.\n",
        "\n",
        "- We created our summary by ranking the highest scoring sentences.\n",
        "\n",
        "- We can now automatically summarize the most critical information from financial texts.\n",
        "\n",
        "Next Up: Web Interface"
      ],
      "metadata": {
        "id": "QUr2ZC43ziqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Streamlit Web Interface"
      ],
      "metadata": {
        "id": "HCtTPZJS0VY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BRcdfmDP0bfw",
        "outputId": "46bde9d1-efba-4b19-9236-759b673985d7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.42.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.27.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.42.2-py2.py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.42.2 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "\n",
        "# Streamlit Interface\n",
        "st.title(\"📄 Financial Text Summarization App\")\n",
        "st.write(\"We help you summarize long financial news and reports by extracting the most important information.\")\n",
        "\n",
        "# Get user input\n",
        "user_input = st.text_area(\"📌 Please enter the financial text you want to summarize:\", \"\")\n",
        "\n",
        "# Summarization Button\n",
        "if st.button(\"Summarize\"):\n",
        "    if user_input.strip():  # Check if input is not empty\n",
        "        sentences = preprocess_text(user_input)  # Process the text\n",
        "        sentence_scores = compute_sentence_scores(sentences, ngram=(1,2))  # Compute sentence scores\n",
        "        summary = select_top_sentences(sentences, sentence_scores, num_sentences=3)  # Generate summary\n",
        "        st.subheader(\"📌 Summary:\")\n",
        "        st.write(summary)\n",
        "    else:\n",
        "        st.warning(\"Please enter a valid text!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "brUaiaFN0gUS",
        "outputId": "a1a943ec-4edf-45a3-a884-9cd279495700"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-25 11:17:19.463 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.574 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-02-25 11:17:19.575 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.578 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.579 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.583 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.584 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.588 Session state does not function when running a script without `streamlit run`\n",
            "2025-02-25 11:17:19.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.590 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.591 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.592 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.593 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.593 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-25 11:17:19.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "gDy3fNTY1xLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we developed a financial text summarization web application using TF-IDF and Streamlit.\n",
        "\n",
        "- We started by preprocessing financial texts, cleaning the data, and splitting it into sentences.\n",
        "\n",
        "- We used TF-IDF with bigrams to rank sentence importance and extract the most relevant information.\n",
        "\n",
        "- We built a user-friendly Streamlit interface, allowing users to input financial texts and generate summaries instantly.\n",
        "\n",
        "- The project is now a functional tool for summarizing financial reports, news, and articles."
      ],
      "metadata": {
        "id": "BZgXEKmQ2Cdd"
      }
    }
  ]
}